{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1b7302-fc7a-4e9b-8c05-4f100ed82b2d",
   "metadata": {},
   "source": [
    "# Fraud Detection - Data Exploration\n",
    "\n",
    "This notebook explores the fraud detection dataset and prepares it for model training.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and explore the Paysim dataset\n",
    "2. Analyze data distribution and characteristics  \n",
    "3. Preprocess and clean the data\n",
    "4. Create train/validation/test splits\n",
    "5. Save processed datasets for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac9ef0-aa0c-4e1c-bba5-74b5d393c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685de5cb-3cfb-4291-8b75-4bec3f01c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "RAW_DIR = \"notebooks/data/raw/\"\n",
    "RAW_CSV_PATH = os.path.join(RAW_DIR, \"paysim.csv\")\n",
    "\n",
    "PROCESSED_DATA_PATH = \"notebook/data/processed/\"\n",
    "FIGURE_PATH = \"notebooks/output/figures/\"\n",
    "\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(FIGURE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb45757-4dd2-4efa-a76d-b043ce95f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data Download\n",
    "# =========================\n",
    "def download_dataset_if_needed():\n",
    "    \"\"\"\n",
    "    Downloads the PaySim dataset using KaggleHub if not already present.\n",
    "    \"\"\"\n",
    "    if os.path.exists(RAW_CSV_PATH):\n",
    "        print(\"PaySim dataset already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    print(\"Downloading PaySim dataset from KaggleHub...\")\n",
    "    dataset_path = kagglehub.dataset_download(\"ealaxi/paysim1\")\n",
    "\n",
    "    csv_found = False\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            src = os.path.join(dataset_path, file)\n",
    "            dst = RAW_CSV_PATH\n",
    "            os.replace(src, dst)\n",
    "            csv_found = True\n",
    "            print(f\"Dataset saved to {RAW_CSV_PATH}\")\n",
    "            break\n",
    "\n",
    "    if not csv_found:\n",
    "        raise FileNotFoundError(\"No CSV file found in downloaded PaySim dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf545d4-b5dd-44bd-8b3c-e5d49546a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data Loading & Processing\n",
    "# =========================\n",
    "def load_data():\n",
    "    download_dataset_if_needed()\n",
    "    print(\"Loading raw PaySim data...\")\n",
    "    return pd.read_csv(RAW_CSV_PATH)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Basic cleaning and label preparation.\n",
    "    \"\"\"\n",
    "    print(\"Cleaning data...\")\n",
    "    df = df.dropna()\n",
    "    df[\"is_fraud\"] = df[\"isFraud\"].astype(int)\n",
    "    return df\n",
    "\n",
    "def create_text_narratives(df):\n",
    "    print(\"Creating enriched transaction narratives...\")\n",
    "\n",
    "    df[\"text\"] = (\n",
    "        \"A financial transaction where account \"\n",
    "        + df[\"nameOrig\"]\n",
    "        + \" sent \"\n",
    "        + df[\"amount\"].astype(str)\n",
    "        + \" units to account \"\n",
    "        + df[\"nameDest\"]\n",
    "        + \" using transaction type \"\n",
    "        + df[\"type\"]\n",
    "        + \". Sender balance changed from \"\n",
    "        + df[\"oldbalanceOrg\"].astype(str)\n",
    "        + \" to \"\n",
    "        + df[\"newbalanceOrig\"].astype(str)\n",
    "        + \". Receiver balance changed from \"\n",
    "        + df[\"oldbalanceDest\"].astype(str)\n",
    "        + \" to \"\n",
    "        + df[\"newbalanceDest\"].astype(str)\n",
    "        + \".\"\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba799ad-f7ad-4478-b2a7-75dc37fbf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Visualization\n",
    "# =========================\n",
    "def visualize_data(df):\n",
    "    \"\"\"\n",
    "    Generates and saves class distribution plots\n",
    "    (absolute count + percentage).\n",
    "    \"\"\"\n",
    "    print(\"Generating visualizations...\")\n",
    "\n",
    "    # ---------- Absolute Count Plot ----------\n",
    "    fraud_counts = df[\"is_fraud\"].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    fraud_counts.plot(kind=\"bar\")\n",
    "    plt.title(\"Fraud vs Non-Fraud Transactions (Count)\")\n",
    "    plt.xlabel(\"Class (0 = Non-Fraud, 1 = Fraud)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURE_PATH, \"fraud_distribution_counts.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------- Percentage Plot ----------\n",
    "    fraud_percent = (\n",
    "        df[\"is_fraud\"]\n",
    "        .value_counts(normalize=True)\n",
    "        .sort_index() * 100\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    fraud_percent.plot(kind=\"bar\")\n",
    "    plt.title(\"Fraud vs Non-Fraud Transactions (Percentage)\")\n",
    "    plt.xlabel(\"Class (0 = Non-Fraud, 1 = Fraud)\")\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "\n",
    "    # Force y-axis to be visible\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    # Annotate bars\n",
    "    for idx, value in enumerate(fraud_percent.values):\n",
    "        plt.text(idx, value + 0.5, f\"{value:.2f}%\", ha=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURE_PATH, \"fraud_distribution_percentage.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved visualization files:\")\n",
    "    print(\" - fraud_distribution_counts.png\")\n",
    "    print(\" - fraud_distribution_percentage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e647d9-c764-4b89-b234-73dbbc5c871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Train / Val / Test Split\n",
    "# =========================\n",
    "def split_and_save(df):\n",
    "    \"\"\"\n",
    "    Splits the dataset into train, validation, and test sets\n",
    "    and saves them to disk.\n",
    "    \"\"\"\n",
    "    print(\"Splitting dataset...\")\n",
    "\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.3,\n",
    "        stratify=df[\"is_fraud\"],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=0.5,\n",
    "        stratify=temp_df[\"is_fraud\"],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_df.to_csv(os.path.join(PROCESSED_DATA_PATH, \"train.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(PROCESSED_DATA_PATH, \"val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(PROCESSED_DATA_PATH, \"test.csv\"), index=False)\n",
    "\n",
    "    print(\"Processed data saved:\")\n",
    "    print(f\"  Train: {len(train_df)} samples\")\n",
    "    print(f\"  Val:   {len(val_df)} samples\")\n",
    "    print(f\"  Test:  {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e249c6-69d8-45cb-bd76-570dfe0af349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Main Pipeline\n",
    "# =========================\n",
    "def main():\n",
    "    df = load_data()\n",
    "    df = clean_data(df)\n",
    "    df = create_text_narratives(df)\n",
    "    visualize_data(df)\n",
    "    split_and_save(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
